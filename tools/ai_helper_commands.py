#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ุฃูุงูุฑ ุณุฑูุนุฉ ููุณุงุนุฏุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ูุฑุฒ ุงููุตูุต
Quick Commands for AI Assistant Text Processing

ุงูุงุณุชุฎุฏุงู:
python ai_helper_commands.py <command> <file> [options]

ุงูุฃูุงูุฑ:
- find_dups: ุงูุนุซูุฑ ุนูู ุงูุชูุฑุงุฑุงุช
- find_similar: ุงูุนุซูุฑ ุนูู ุงูุชุดุงุจูุงุช  
- search: ุงูุจุญุซ ุนู ูุตุทูุญ
- map: ุฎุฑูุทุฉ ุงููุตุทูุญุงุช
- structure: ุชุญููู ุงููููู
- report: ุชูุฑูุฑ ุดุงูู
"""

import sys
import os
from ai_assistant_helper import AIAssistantHelper, QuickAssistant, ai_assistant_workflow

def show_usage():
    """ุนุฑุถ ุทุฑููุฉ ุงูุงุณุชุฎุฏุงู"""
    print("""
๐ค ุฃูุงูุฑ ูุณุงุนุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู

ุงูุงุณุชุฎุฏุงู:
  python ai_helper_commands.py <command> <file> [options]

ุงูุฃูุงูุฑ ุงููุชุงุญุฉ:

๐ ุฃูุงูุฑ ุงูุชูุฑุงุฑุงุช ูุงูุชุดุงุจู:
  find_dups <file>              - ุงูุนุซูุฑ ุนูู ุงูุชูุฑุงุฑุงุช ุงููุทุงุจูุฉ
  find_similar <file> [threshold] - ุงูุนุซูุฑ ุนูู ุงูุชุดุงุจูุงุช (ุงูุชุฑุงุถู: 0.7)
  
๐ ุฃูุงูุฑ ุงูุจุญุซ:
  search <file> <term>          - ุงูุจุญุซ ุนู ูุตุทูุญ ูุญุฏุฏ
  search_context <file> <term> [context_words] - ุงูุจุญุซ ูุน ุชุฌููุน ุงูุณูุงู
  search_multi <file> <term1,term2,term3> - ุงูุจุญุซ ุนู ุนุฏุฉ ูุตุทูุญุงุช
  pattern <file> <regex>        - ุงูุจุญุซ ุจููุท regex
  related <file> <term1,term2,term3> - ุงูุนุซูุฑ ุนูู ุงูููุงููู ุงููุชุฑุงุจุทุฉ
  
๐บ๏ธ ุฃูุงูุฑ ุงูุชุญููู:
  map <file> <term1,term2>      - ุฎุฑูุทุฉ ุงููุตุทูุญุงุช ูุน ุฃุฑูุงู ุงูุฃุณุทุฑ
  structure <file>              - ุชุญููู ูููู ุงููุต (ุนูุงูููุ ูุนุงุฏูุงุชุ ุฅูุฎ)
  
๐ ุฃูุงูุฑ ุงูุชูุงุฑูุฑ:
  report <file>                 - ุชูุฑูุฑ ุดุงูู ููุฐูุงุก ุงูุงุตุทูุงุนู
  quick_check <file>            - ูุญุต ุณุฑูุน ูููุดุงูู ุงูุดุงุฆุนุฉ

๐งน ุฃูุงูุฑ ุงููุฑุฒ ุงูุฐูู:
  remove_ai <file>              - ุญุฐู ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู
  extract_method <file> <method_name> <keyword1,keyword2> - ุงุณุชุฎุฑุงุฌ ุทุฑููุฉ ุญู
  smart_sort <file>             - ุงููุฑุฒ ุงูุฐูู ุงููุงูู
  
๐ฏ ุฃูุงูุฑ ุฎุงุตุฉ:
  interactive <file>            - ูุถุน ุชูุงุนูู ููุจุญุซ ุงููุชูุฏู
  help                          - ุนุฑุถ ูุฐู ุงููุณุงุนุฏุฉ

ุฃูุซูุฉ:
  python ai_helper_commands.py find_dups riemann_research_ideas.md
  python ai_helper_commands.py search conversation_archive.txt "ูุงููุชููู"
  python ai_helper_commands.py map riemann_research_ideas.md "ุทูู,ูููุฉ ุฐุงุชูุฉ,ุจุฑูุงู"
  python ai_helper_commands.py report riemann_research_ideas.md
    """)

def cmd_find_dups(file_path: str):
    """ุฃูุฑ ุงูุนุซูุฑ ุนูู ุงูุชูุฑุงุฑุงุช"""
    print("๐ ุงูุจุญุซ ุนู ุงูุชูุฑุงุฑุงุช ุงููุทุงุจูุฉ...")
    result = QuickAssistant.quick_find_duplicates(file_path)
    print(result)

def cmd_find_similar(file_path: str, threshold: str = "0.7"):
    """ุฃูุฑ ุงูุนุซูุฑ ุนูู ุงูุชุดุงุจูุงุช"""
    try:
        thresh = float(threshold)
        print(f"๐ ุงูุจุญุซ ุนู ุงูุชุดุงุจูุงุช (ุนุชุจุฉ: {thresh})...")
        result = QuickAssistant.quick_similarity_check(file_path, thresh)
        print(result)
    except ValueError:
        print("โ ุนุชุจุฉ ุงูุชุดุงุจู ูุฌุจ ุฃู ุชููู ุฑูู ุจูู 0 ู 1")

def cmd_search(file_path: str, term: str):
    """ุฃูุฑ ุงูุจุญุซ ุนู ูุตุทูุญ"""
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return

    print(f"๐ ุงูุจุญุซ ุนู: '{term}'")
    results = helper.search_concept(term, context_lines=1)

    if not results:
        print("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ")
        return

    print(f"๐ ุชู ุงูุนุซูุฑ ุนูู {len(results)} ูุชูุฌุฉ:")
    for i, result in enumerate(results[:20]):  # ุฃูู 20 ูุชูุฌุฉ
        print(f"\n{i+1}. ุงูุณุทุฑ {result['line_number']}:")
        print(f"   {result['content']}")

def cmd_search_context(file_path: str, term: str, context_words: str = "10"):
    """ุฃูุฑ ุงูุจุญุซ ูุน ุชุฌููุน ุงูุณูุงู"""
    try:
        context_size = int(context_words)
        helper = AIAssistantHelper(context_words=context_size)
        if not helper.load_file(file_path):
            return

        print(f"๐ ุงูุจุญุซ ูุน ุงูุณูุงู: '{term}' (ูุนุงูู: {context_size})")
        results = helper.search_concept_with_context(term)

        if not results:
            print("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ")
            return

        print(f"๐ ุชู ุงูุนุซูุฑ ุนูู {len(results)} ุณูุงู ูุชุฑุงุจุท:")
        for i, result in enumerate(results[:10]):  # ุฃูู 10 ุณูุงูุงุช
            print(f"\n{i+1}. ุงูุณูุงู {result['context_start']}-{result['context_end']} ({result['matches_count']} ุชุทุงุจู):")
            print(f"   ุงูุฃุณุทุฑ: {', '.join(map(str, result['line_numbers']))}")
            print(f"   ุนุฏุฏ ุงููููุงุช: {result['word_count']}")
            print("   ุงููุญุชูู:")
            for line in result['context_text'][:5]:  # ุฃูู 5 ุฃุณุทุฑ ูู ุงูุณูุงู
                print(f"     {line}")
            if len(result['context_text']) > 5:
                print(f"     ... ู {len(result['context_text']) - 5} ุณุทุฑ ุขุฎุฑ")

    except ValueError:
        print("โ ูุนุงูู ุงูุณูุงู ูุฌุจ ุฃู ูููู ุฑูู")

def cmd_search_multi(file_path: str, terms_str: str):
    """ุฃูุฑ ุงูุจุญุซ ุนู ุนุฏุฉ ูุตุทูุญุงุช"""
    terms = [t.strip() for t in terms_str.split(',')]
    print(f"๐ ุงูุจุญุซ ุนู {len(terms)} ูุตุทูุญุงุช...")
    result = QuickAssistant.quick_search_multiple(file_path, terms)
    print(result)

def cmd_pattern(file_path: str, pattern: str):
    """ุฃูุฑ ุงูุจุญุซ ุจููุท regex"""
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return
    
    print(f"๐ ุงูุจุญุซ ุจุงูููุท: '{pattern}'")
    results = helper.find_ideas_by_pattern(pattern)
    
    if not results:
        print("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ")
        return
    
    print(f"๐ ุชู ุงูุนุซูุฑ ุนูู {len(results)} ูุชูุฌุฉ:")
    for i, result in enumerate(results[:15]):
        print(f"{i+1}. ุงูุณุทุฑ {result['line_number']}: {result['match']}")

def cmd_map(file_path: str, terms_str: str):
    """ุฃูุฑ ุฎุฑูุทุฉ ุงููุตุทูุญุงุช"""
    terms = [t.strip() for t in terms_str.split(',')]
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return
    
    print(f"๐บ๏ธ ุฅูุดุงุก ุฎุฑูุทุฉ ูู {len(terms)} ูุตุทูุญุงุช...")
    line_map = helper.generate_line_map(terms)
    
    print("๐ ุฎุฑูุทุฉ ุงููุตุทูุญุงุช:")
    for term, locations in line_map.items():
        if locations:
            line_numbers = [str(loc['line_number']) for loc in locations]
            print(f"\n'{term}' ({len(locations)} ูุฑุฉ):")
            print(f"  ุงูุฃุณุทุฑ: {', '.join(line_numbers[:20])}")
            if len(locations) > 20:
                print(f"  ... ู {len(locations) - 20} ูููุน ุขุฎุฑ")
        else:
            print(f"\n'{term}': ูู ูุชู ุงูุนุซูุฑ ุนููู")

def cmd_structure(file_path: str):
    """ุฃูุฑ ุชุญููู ุงููููู"""
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return
    
    print("๐ ุชุญููู ูููู ุงููุต...")
    structure = helper.analyze_section_structure()
    
    print("\n๐ ุชูุฑูุฑ ุงููููู:")
    for section_type, items in structure.items():
        print(f"\n{section_type} ({len(items)} ุนูุตุฑ):")
        if items:
            for i, item in enumerate(items[:10]):  # ุฃูู 10 ุนูุงุตุฑ
                print(f"  {i+1}. ุงูุณุทุฑ {item['line_number']}: {item['match'][:80]}...")
            if len(items) > 10:
                print(f"  ... ู {len(items) - 10} ุนูุตุฑ ุขุฎุฑ")

def cmd_report(file_path: str):
    """ุฃูุฑ ุงูุชูุฑูุฑ ุงูุดุงูู"""
    print("๐ ุฅูุชุงุฌ ุชูุฑูุฑ ุดุงูู ููุฐูุงุก ุงูุงุตุทูุงุนู...")
    ai_assistant_workflow(file_path, "full_analysis")

def cmd_quick_check(file_path: str):
    """ุฃูุฑ ุงููุญุต ุงูุณุฑูุน"""
    print("โก ูุญุต ุณุฑูุน ูููุดุงูู ุงูุดุงุฆุนุฉ...")
    ai_assistant_workflow(file_path, "quick_check")

def cmd_related(file_path: str, terms_str: str):
    """ุฃูุฑ ุงูุนุซูุฑ ุนูู ุงูููุงููู ุงููุชุฑุงุจุทุฉ"""
    terms = [t.strip() for t in terms_str.split(',')]
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return

    print(f"๐ ุงูุจุญุซ ุนู ุงูููุงููู ุงููุชุฑุงุจุทุฉ: {', '.join(terms)}")
    results = helper.find_related_concepts(terms)

    print(f"\n๐ ููุงูุน ุงูููุงููู:")
    for concept, locations in results['concept_locations'].items():
        if locations:
            print(f"  '{concept}': {len(locations)} ูุฑุฉ ูู ุงูุฃุณุทุฑ {', '.join(map(str, locations[:10]))}")
            if len(locations) > 10:
                print(f"    ... ู {len(locations) - 10} ูููุน ุขุฎุฑ")

    related_groups = results['related_groups']
    if related_groups:
        print(f"\n๐ ุงููุฌููุนุงุช ุงููุชุฑุงุจุทุฉ ({len(related_groups)}):")

        # ุชุฌููุน ุญุณุจ ุงูููุงููู ุงููุชุฑุงุจุทุฉ
        unique_groups = {}
        for group in related_groups:
            key = tuple(sorted(group['related_concepts']))
            if key not in unique_groups:
                unique_groups[key] = []
            unique_groups[key].append(group)

        for i, (concepts, groups) in enumerate(unique_groups.items(), 1):
            print(f"\n{i}. ุงูููุงููู ุงููุชุฑุงุจุทุฉ: {', '.join(concepts)}")
            print(f"   ุนุฏุฏ ุงูุณูุงูุงุช: {len(groups)}")
            print(f"   ุงูุฃุณุทุฑ: {', '.join(str(g['center_line']) for g in groups[:5])}")
            if len(groups) > 5:
                print(f"   ... ู {len(groups) - 5} ุณูุงู ุขุฎุฑ")
    else:
        print("\nโ ูู ูุชู ุงูุนุซูุฑ ุนูู ููุงููู ูุชุฑุงุจุทุฉ")

def cmd_remove_ai(file_path: str):
    """ุฃูุฑ ุญุฐู ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return

    print("๐ค ุชุญุฏูุฏ ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ููุญุฐู...")
    removed_sections = helper.remove_ai_responses()

    if removed_sections:
        print(f"๐ ุงูุฃูุณุงู ุงููุญุฏุฏุฉ ููุญุฐู:")
        for i, (start, end) in enumerate(removed_sections[:10], 1):
            print(f"  {i}. ุงูุฃุณุทุฑ {start}-{end}")

        if len(removed_sections) > 10:
            print(f"  ... ู {len(removed_sections) - 10} ูุณู ุขุฎุฑ")

        # ุญูุธ ูุงุฆูุฉ ุจุงูุฃูุณุงู ุงููุญุฐููุฉ
        with open('ai_responses_to_remove.txt', 'w', encoding='utf-8') as f:
            f.write("ุฃูุณุงู ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุญุฏุฏุฉ ููุญุฐู:\n\n")
            for start, end in removed_sections:
                f.write(f"ุงูุฃุณุทุฑ {start}-{end}\n")

        print(f"๐พ ุชู ุญูุธ ุงููุงุฆูุฉ ูู: ai_responses_to_remove.txt")
    else:
        print("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ุฑุฏูุฏ ุฐูุงุก ุงุตุทูุงุนู ูุงุถุญุฉ")

def cmd_extract_method(file_path: str, method_name: str, keywords_str: str):
    """ุฃูุฑ ุงุณุชุฎุฑุงุฌ ุทุฑููุฉ ุญู ูุญุฏุฏุฉ"""
    keywords = [k.strip() for k in keywords_str.split(',')]
    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return

    print(f"๐ฌ ุงุณุชุฎุฑุงุฌ ุทุฑููุฉ: {method_name}")
    method_data = helper.extract_solution_method(keywords, method_name)

    if method_data['sections']:
        print(f"๐ ุชู ุงูุนุซูุฑ ุนูู {method_data['total_sections']} ูุณู:")

        for i, section in enumerate(method_data['sections'], 1):
            print(f"\n{i}. ุงูุฃุณุทุฑ {section['start_line']}-{section['end_line']}:")
            print(f"   ุงููููุฉ ุงูููุชุงุญูุฉ: {section['trigger_keyword']}")
            print(f"   ุนุฏุฏ ุงููููุงุช: {section['word_count']}")
            print(f"   ุนุฏุฏ ุงูุฃุณุทุฑ: {section['line_count']}")

            # ุนุฑุถ ุจุฏุงูุฉ ุงููุต
            preview = section['text'][:200] + "..." if len(section['text']) > 200 else section['text']
            print(f"   ุงููุนุงููุฉ: {preview}")

        # ููุงุฑูุฉ ุงููุณุฎ
        if len(method_data['sections']) > 1:
            print(f"\nโ๏ธ ููุงุฑูุฉ ุงููุณุฎ...")
            comparison = helper.compare_method_versions(method_data['sections'])

            print(f"๐ ุงูุชูุตูุฉ: {comparison['recommendation']}")
            if comparison['recommendation'] == 'keep_best':
                best_section = comparison['sections'][0]
                print(f"๐ ุฃูุถู ูุณุฎุฉ: ุงูุฃุณุทุฑ {best_section['start_line']}-{best_section['end_line']} (ุฏุฑุฌุฉ: {best_section['quality_score']:.2f})")
            elif comparison['recommendation'] == 'keep_all':
                print("๐ ุงููุณุฎ ูุฎุชููุฉ ุจูุง ูููู ููุงุญุชูุงุธ ุจูุง ุฌููุนุงู")
            else:
                print("โ๏ธ ูููุตุญ ุจุงููุฑุงุฌุนุฉ ุงููุฏููุฉ")

        # ุญูุธ ุงููุชุงุฆุฌ
        output_file = f"method_{method_name.replace(' ', '_')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(method_data, f, ensure_ascii=False, indent=2)

        print(f"๐พ ุชู ุญูุธ ุงูุชูุงุตูู ูู: {output_file}")
    else:
        print("โ ูู ูุชู ุงูุนุซูุฑ ุนูู ุฃูุณุงู ููุฐู ุงูุทุฑููุฉ")

def cmd_smart_sort(file_path: str):
    """ุฃูุฑ ุงููุฑุฒ ุงูุฐูู ุงููุงูู"""
    print("๐ง ุจุฏุก ุงููุฑุฒ ุงูุฐูู ุงููุงูู...")

    # ุทุฑู ุงูุญู ุงููุนุฑููุฉ
    solution_methods = {
        'ุงูุทูู ุงูุนุฏุฏู': ['ุทูู', 'ูุงููุชููู', 'ูููุฉ ุฐุงุชูุฉ', 'ูุดุบู'],
        'ูุธุฑูุฉ RLC': ['rlc', 'ููุงููุฉ', 'ูุญุงุซุฉ', 'ุณุนุฉ', 'ุฏุงุฆุฑุฉ'],
        'ุงูุชุดุชุช ุงูููููู': ['ุชุดุชุช', 'ููุฌุฉ', 'ุงูุชุดุงุฑ', 'ุชุฏุงุฎู'],
        'ูุธุฑูุฉ ูููุจุฑุช': ['ูููุจุฑุช', 'ูุถุงุก', 'ูุชุฌู', 'ุฅุณูุงุท'],
        'ุงูุชุญููู ุงูุทููู': ['ููุฑููู', 'ุชุญููู', 'ุชุฑุฏุฏ', 'ุทูู'],
        'ุงููุธุฑูุฉ ุงููููููุฉ': ['ููููู', 'ููุงูุชู', 'ูููุงูููุง', 'ุญุงูุฉ']
    }

    helper = AIAssistantHelper()
    if not helper.load_file(file_path):
        return

    print("1๏ธโฃ ุญุฐู ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู...")
    removed_sections = helper.remove_ai_responses()
    print(f"   ุชู ุชุญุฏูุฏ {len(removed_sections)} ูุณู ููุญุฐู")

    print("\n2๏ธโฃ ุงุณุชุฎุฑุงุฌ ุทุฑู ุงูุญู...")
    extracted_methods = {}

    for method_name, keywords in solution_methods.items():
        print(f"   ๐ฌ ุงุณุชุฎุฑุงุฌ: {method_name}")
        method_data = helper.extract_solution_method(keywords, method_name)

        if method_data['sections']:
            extracted_methods[method_name] = method_data
            print(f"      โ {method_data['total_sections']} ูุณู")
        else:
            print(f"      โ ูุง ุชูุฌุฏ ุฃูุณุงู")

    print(f"\n๐ ููุฎุต ุงููุฑุฒ:")
    print(f"   ุฑุฏูุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู: {len(removed_sections)} ูุณู")
    print(f"   ุทุฑู ุงูุญู ุงููุณุชุฎุฑุฌุฉ: {len(extracted_methods)}")

    total_extracted_sections = sum(len(data['sections']) for data in extracted_methods.values())
    print(f"   ุฅุฌูุงูู ุงูุฃูุณุงู ุงููุณุชุฎุฑุฌุฉ: {total_extracted_sections}")

    # ุญูุธ ุงููุชุงุฆุฌ ุงูุดุงููุฉ
    with open('smart_sort_results.json', 'w', encoding='utf-8') as f:
        import json
        results = {
            'removed_ai_sections': removed_sections,
            'extracted_methods': extracted_methods,
            'summary': {
                'ai_sections_count': len(removed_sections),
                'methods_count': len(extracted_methods),
                'total_sections': total_extracted_sections
            }
        }
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"๐พ ุชู ุญูุธ ุงููุชุงุฆุฌ ุงูุดุงููุฉ ูู: smart_sort_results.json")

def cmd_interactive(file_path: str):
    """ุฃูุฑ ุงููุถุน ุงูุชูุงุนูู"""
    helper = AIAssistantHelper()
    if helper.load_file(file_path):
        helper.interactive_search()

def main():
    """ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ"""
    if len(sys.argv) < 2:
        show_usage()
        return
    
    command = sys.argv[1].lower()
    
    if command == "help":
        show_usage()
        return
    
    if len(sys.argv) < 3:
        print("โ ูุฌุจ ุชุญุฏูุฏ ููู ูููุนุงูุฌุฉ")
        print("ุงุณุชุฎุฏู: python ai_helper_commands.py help ูููุณุงุนุฏุฉ")
        return
    
    file_path = sys.argv[2]
    
    if not os.path.exists(file_path):
        print(f"โ ุงูููู ุบูุฑ ููุฌูุฏ: {file_path}")
        return
    
    # ุชูููุฐ ุงูุฃูุงูุฑ
    try:
        if command == "find_dups":
            cmd_find_dups(file_path)
        
        elif command == "find_similar":
            threshold = sys.argv[3] if len(sys.argv) > 3 else "0.7"
            cmd_find_similar(file_path, threshold)
        
        elif command == "search":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ูุตุทูุญ ุงูุจุญุซ")
                return
            term = sys.argv[3]
            cmd_search(file_path, term)

        elif command == "search_context":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ูุตุทูุญ ุงูุจุญุซ")
                return
            term = sys.argv[3]
            context_words = sys.argv[4] if len(sys.argv) > 4 else "10"
            cmd_search_context(file_path, term, context_words)
        
        elif command == "search_multi":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ุงููุตุทูุญุงุช ููุตููุฉ ุจููุงุตู")
                return
            terms = sys.argv[3]
            cmd_search_multi(file_path, terms)
        
        elif command == "pattern":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ููุท ุงูุจุญุซ")
                return
            pattern = sys.argv[3]
            cmd_pattern(file_path, pattern)
        
        elif command == "map":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ุงููุตุทูุญุงุช ููุตููุฉ ุจููุงุตู")
                return
            terms = sys.argv[3]
            cmd_map(file_path, terms)

        elif command == "related":
            if len(sys.argv) < 4:
                print("โ ูุฌุจ ุชุญุฏูุฏ ุงููุตุทูุญุงุช ููุตููุฉ ุจููุงุตู")
                return
            terms = sys.argv[3]
            cmd_related(file_path, terms)
        
        elif command == "structure":
            cmd_structure(file_path)
        
        elif command == "report":
            cmd_report(file_path)
        
        elif command == "quick_check":
            cmd_quick_check(file_path)
        
        elif command == "remove_ai":
            cmd_remove_ai(file_path)

        elif command == "extract_method":
            if len(sys.argv) < 5:
                print("โ ูุฌุจ ุชุญุฏูุฏ ุงุณู ุงูุทุฑููุฉ ูุงููููุงุช ุงูููุชุงุญูุฉ")
                print("ูุซุงู: extract_method file.md 'ุงูุทูู ุงูุนุฏุฏู' 'ุทูู,ูุงููุชููู,ูููุฉ ุฐุงุชูุฉ'")
                return
            method_name = sys.argv[3]
            keywords = sys.argv[4]
            cmd_extract_method(file_path, method_name, keywords)

        elif command == "smart_sort":
            cmd_smart_sort(file_path)

        elif command == "interactive":
            cmd_interactive(file_path)

        else:
            print(f"โ ุฃูุฑ ุบูุฑ ูุนุฑูู: {command}")
            print("ุงุณุชุฎุฏู: python ai_helper_commands.py help ูููุณุงุนุฏุฉ")
    
    except KeyboardInterrupt:
        print("\nโน๏ธ ุชู ุฅููุงู ุงูุนูููุฉ")
    except Exception as e:
        print(f"โ ุฎุทุฃ: {e}")

if __name__ == "__main__":
    main()
